{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 117, 1024]), torch.Size([1, 117]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loader_new import get_loader\n",
    "from config import Config\n",
    "from solver import get_device, Solver\n",
    "\n",
    "device = get_device()\n",
    "train_config = Config()\n",
    "test_config = Config(mode='test')\n",
    "train_loader, test_loader = get_loader(video_type=\"summe\", split_index=0)\n",
    "\n",
    "for batch in train_loader:\n",
    "    break\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "mapping_dict = {1: 'Air_Force_One',\n",
    "                10: 'Excavators river crossing',\n",
    "                11: 'Fire Domino',\n",
    "                12: 'Jumps',\n",
    "                13: 'Kids_playing_in_leaves',\n",
    "                14: 'Notre_Dame',\n",
    "                15: 'Paintball',\n",
    "                16: 'Playing_on_water_slide',\n",
    "                17: 'Saving dolphines',\n",
    "                18: 'Scuba',\n",
    "                19: 'St Maarten Landing',\n",
    "                2: 'Base jumping',\n",
    "                20: 'Statue of Liberty',\n",
    "                21: 'Uncut_Evening_Flight',\n",
    "                22: 'Valparaiso_Downhill',\n",
    "                23: 'car_over_camera',\n",
    "                24: 'paluma_jump',\n",
    "                25: 'playing_ball',\n",
    "                3: 'Bearpark_climbing',\n",
    "                4: 'Bike Polo',\n",
    "                5: 'Bus_in_Rock_Tunnel',\n",
    "                6: 'Car_railcrossing',\n",
    "                7: 'Cockpit_Landing',\n",
    "                8: 'Cooking',\n",
    "                9: 'Eiffel Tower'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_1\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (30, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (30,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 4494), type \"<f4\">}\n",
      "video_10\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (65, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (65,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 9721), type \"<f4\">}\n",
      "video_11\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (11, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (11,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 1612), type \"<f4\">}\n",
      "video_12\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (7, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (7,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 950), type \"<f4\">}\n",
      "video_13\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (22, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (22,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 3187), type \"<f4\">}\n",
      "video_14\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (31, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (31,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 4608), type \"<f4\">}\n",
      "video_15\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (41, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (41,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (17, 6096), type \"<f4\">}\n",
      "video_16\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (21, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (21,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 3065), type \"<f4\">}\n",
      "video_17\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (45, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (45,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 6683), type \"<f4\">}\n",
      "video_18\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (15, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (15,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (17, 2221), type \"<f4\">}\n",
      "video_19\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (12, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (12,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (17, 1751), type \"<f4\">}\n",
      "video_2\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (32, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (32,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (18, 4729), type \"<f4\">}\n",
      "video_20\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (26, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (26,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (17, 3863), type \"<f4\">}\n",
      "video_21\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (65, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (65,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 9672), type \"<f4\">}\n",
      "video_22\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (35, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (35,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 5178), type \"<f4\">}\n",
      "video_23\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (30, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (30,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 4382), type \"<f4\">}\n",
      "video_24\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (18, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (18,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 2574), type \"<f4\">}\n",
      "video_25\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (21, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (21,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (16, 3120), type \"<f4\">}\n",
      "video_3\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (23, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (23,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 3341), type \"<f4\">}\n",
      "video_4\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (21, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (21,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 3064), type \"<f4\">}\n",
      "video_5\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (35, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (35,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 5131), type \"<f4\">}\n",
      "video_6\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (34, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (34,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (16, 5075), type \"<f4\">}\n",
      "video_7\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (61, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (61,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 9046), type \"<f4\">}\n",
      "video_8\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (9, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (9,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (17, 1286), type \"<f4\">}\n",
      "video_9\n",
      "{'change_points': <HDF5 dataset \"change_points\": shape (34, 2), type \"<i8\">, 'feature': <HDF5 dataset \"feature\": shape (320, 1024), type \"<f4\">, 'label': <HDF5 dataset \"label\": shape (320,), type \"<f8\">, 'length': <HDF5 dataset \"length\": shape (), type \"<i8\">, 'n_frame_per_seg': <HDF5 dataset \"n_frame_per_seg\": shape (34,), type \"<i8\">, 'picks': <HDF5 dataset \"picks\": shape (320,), type \"<i8\">, 'user_summary': <HDF5 dataset \"user_summary\": shape (15, 4971), type \"<f4\">}\n"
     ]
    }
   ],
   "source": [
    "data_file = h5py.File(\"./data/SumMe/fcsn_summe.h5\")\n",
    "for i in data_file:\n",
    "    print(str(i))\n",
    "    print(dict(data_file[str(i)]))\n",
    "    # data_file[str(i)][\"video_name\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(train_config, train_loader, test_loader, max_seq=320, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dfc04867ce44bca894d966f7c3ad4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9047fbda5ae8410b95228ed2a38aa9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/test.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/test.ipynb#ch0000004?line=0'>1</a>\u001b[0m solver\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py:106\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py?line=102'>103</a>\u001b[0m feature\u001b[39m.\u001b[39mrequires_grad_()\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py?line=104'>105</a>\u001b[0m \u001b[39m# ---- Train ---- #\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py?line=105'>106</a>\u001b[0m pred_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(feature)\u001b[39m*\u001b[39mmask\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py?line=108'>109</a>\u001b[0m label_1 \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39msum()\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/solver.py?line=109'>110</a>\u001b[0m label_0 \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m label_1\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py:99\u001b[0m, in \u001b[0;36mFCSN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py?line=96'>97</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[1;32m     <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py?line=97'>98</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(h)\n\u001b[0;32m---> <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py?line=98'>99</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(h)\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py?line=99'>100</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(h)\n\u001b[1;32m    <a href='file:///home/suong/Documents/code/RESEARCH/HCMUS/Videosum/FCSN/fcsn.py?line=100'>101</a>\u001b[0m pool4 \u001b[39m=\u001b[39m h\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:167\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=159'>160</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=161'>162</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=162'>163</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=163'>164</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=164'>165</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=165'>166</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=166'>167</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=167'>168</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=168'>169</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=169'>170</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=170'>171</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=171'>172</a>\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=172'>173</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=173'>174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=175'>176</a>\u001b[0m     bn_training,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=176'>177</a>\u001b[0m     exponential_average_factor,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=178'>179</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py:2281\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py?line=2277'>2278</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py?line=2278'>2279</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py?line=2280'>2281</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py?line=2281'>2282</a>\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   <a href='file:///home/suong/miniconda3/envs/cv/lib/python3.8/site-packages/torch/nn/functional.py?line=2282'>2283</a>\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solver.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c16d26dcc6bd2940569404d6072e3dba263608c5350ed75a30cef2c781b8b930"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
